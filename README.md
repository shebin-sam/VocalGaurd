
# VocalGuard: Real-time Toxicity Detection for Speech-to-Text Transcription
Description
VocalGuard is a project designed to detect toxic speech in real-time by converting speech to text and utilizing LSTM models trained on the Kaggle Jigsaw Comment Classification Challenge dataset. It aims to provide a safer and more inclusive communication environment by promptly notifying users of any toxic speech.

## Features
1.Real-time conversion of speech to text<br />
2.Detection of toxic speech using LSTM models<br />
3.Immediate notification of toxic speech<br />

## Dataset
The project utilizes the Kaggle Jigsaw Comment Classification Challenge dataset. You can find the dataset at https://www.kaggle.com/datasets/julian3833/jigsaw-toxic-comment-classification-challenge
